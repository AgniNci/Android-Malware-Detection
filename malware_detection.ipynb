{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "1EY6NURPCdic"
      },
      "id": "1EY6NURPCdic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86d6dd3",
      "metadata": {
        "id": "e86d6dd3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from androguard.misc import AnalyzeAPK\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randrange\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import glob\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import hashlib\n",
        "import keras_tuner as kt\n",
        "from kerastuner import HyperParameter, HyperParameters\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband\n",
        "from xml.etree import ElementTree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only required while running the notebook on colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "EuFngzUd7sDb"
      },
      "id": "EuFngzUd7sDb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "801aebd9",
      "metadata": {
        "id": "801aebd9"
      },
      "source": [
        "# Load Apk Data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f84914b",
      "metadata": {
        "id": "6f84914b"
      },
      "outputs": [],
      "source": [
        "#apk_data.csv is available in the project directory. This file holds all the information about apks \n",
        "df_apk = pd.read_csv(\"apk_data.csv\")\n",
        "df_apk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f75f052",
      "metadata": {
        "id": "3f75f052"
      },
      "outputs": [],
      "source": [
        "df_apk['is_malicious'] = df_apk['label'].apply(lambda x : 0 if \"Benign\" in x else 1)\n",
        "df_apk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc356ffa",
      "metadata": {
        "id": "fc356ffa"
      },
      "source": [
        " # Convert APK to Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033caaa1",
      "metadata": {
        "id": "033caaa1"
      },
      "outputs": [],
      "source": [
        "#Resizing all channels to a fixed shape by using Nearest neighbour interpolation\n",
        "def OneD2TwoD_resize(image_pixels, channel, dim):\n",
        "    if len(image_pixels) == 0:\n",
        "        return np.zeros((dim, dim), dtype = np.float32)\n",
        "    h = int(len(image_pixels)**0.5)\n",
        "    w = int(len(image_pixels)/h)\n",
        "#     print(f'{channel} Channel Pixels Length:{len(image_pixels)}  Height:{h}  Width:{w}')\n",
        "    unused_valus = len(image_pixels) - h*w\n",
        "    inc = 0\n",
        "    if(unused_valus != 0):\n",
        "        unused_valus = len(image_pixels) - h*w\n",
        "        empty_spots = w-unused_valus\n",
        "        i = unused_valus\n",
        "        j = unused_valus+empty_spots\n",
        "        image_pixels += image_pixels[-j:-i]\n",
        "        inc+=1\n",
        "    \n",
        "    image_pixels = np.array(image_pixels)\n",
        "    twoD_image = image_pixels.reshape(h+inc,w)\n",
        "    \n",
        "    twoD_image = twoD_image.astype('float32')\n",
        "    image_resized = cv2.resize(twoD_image, (dim, dim), interpolation = cv2.INTER_NEAREST)# INTER_LINEAR\n",
        "    return image_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917dd53d",
      "metadata": {
        "id": "917dd53d"
      },
      "outputs": [],
      "source": [
        "#Convert properties from classes.dex file to integers (pixel values) in range [0,255]\n",
        "def dex2Image(dx, dim):\n",
        "    #Convert APIs to pixel values\n",
        "    API_calls_pixels = API_calls2pixels(dx)\n",
        "    #Convert Opcodes to pixel values\n",
        "    opcodes_pixls = opcodes2pixels(dx)\n",
        "    red_channel = OneD2TwoD_resize(API_calls_pixels, \"Red\", dim)\n",
        "    blue_channel = OneD2TwoD_resize(opcodes_pixls, \"Blue\", dim)\n",
        "    return red_channel, blue_channel\n",
        "\n",
        "#Convert API calls to pixel values\n",
        "def API_calls2pixels(dx):\n",
        "    API_calls = []\n",
        "    for api in dx.get_external_classes():\n",
        "        api_tmp = api.get_vm_class()\n",
        "        for i in api_tmp.get_methods():\n",
        "            api_call = str(i).split('(')[0] # ignoring parameters and return type.\n",
        "            API_calls.append(int(sum(api_call.encode())%256))\n",
        "    return API_calls\n",
        "\n",
        "#Convert opcodes to pixel values\n",
        "def opcodes2pixels(dx):\n",
        "    sequences = []\n",
        "    for method in dx.get_methods():\n",
        "        if method.is_external():\n",
        "            continue\n",
        "        m = method.get_method()\n",
        "        opcodes = []\n",
        "        for ins in m.get_instructions():\n",
        "            opcodes.append(ins.get_name())\n",
        "        sequences.append(int(sum(\"\".join(opcodes).encode())%256))\n",
        "    return sequences\n",
        "\n",
        "#Convert protected strings to pixel values\n",
        "def strings2pixels(d):\n",
        "    string_pixels = []\n",
        "    all_strings = d[0].get_strings()\n",
        "    [string_pixels.append((sum(strng.encode()))%256) for strng in all_strings]\n",
        "    return string_pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f6a77d",
      "metadata": {
        "id": "d8f6a77d"
      },
      "outputs": [],
      "source": [
        "#Convert properties from AndroidMAnifest.xml file to pixel values\n",
        "def manifest2Image(a,d,dim):\n",
        "    manifest_pixels = []\n",
        "    if a.get_androidversion_code():\n",
        "        manifest_pixels.append(sum(a.get_androidversion_code().encode())%256)\n",
        "    if a.get_androidversion_name():\n",
        "        manifest_pixels.append(sum(a.get_androidversion_name().encode())%256)\n",
        "    if a.get_max_sdk_version():\n",
        "        manifest_pixels.append(sum(a.get_max_sdk_version().encode())%256)\n",
        "    if a.get_min_sdk_version():\n",
        "        manifest_pixels.append(sum(a.get_min_sdk_version().encode())%256)\n",
        "    if a.get_target_sdk_version():\n",
        "        manifest_pixels.append(sum(a.get_target_sdk_version().encode())%256)\n",
        "    if a.get_main_activity():\n",
        "        manifest_pixels.append(sum(a.get_main_activity().encode())%256)\n",
        "    manifest_pixels.append(sum(a.get_package().encode())%256)\n",
        "     #Permissions\n",
        "    permissions = a.get_permissions() + a.get_declared_permissions()\n",
        "    #print(f'Permissions : {permissions}')\n",
        "    for permission in permissions:\n",
        "        perm = permission.split('.')[-1]\n",
        "        manifest_pixels.append(sum(perm.encode())%256)\n",
        "        \n",
        "    aosp_permissions = a.get_requested_aosp_permissions()\n",
        "    #print(f'Permissions : {aosp_permissions}')\n",
        "    for permission in aosp_permissions:\n",
        "        aosp_perm = permission.split('.')[-1]\n",
        "        #print(f'AOSP : {aosp_perm}')\n",
        "        manifest_pixels.append(sum(aosp_perm.encode())%256)\n",
        "        \n",
        "    third_party_permissions = a.get_requested_third_party_permissions()\n",
        "    #print(f'Permissions : {third_party_permissions}')\n",
        "    for permission in third_party_permissions:\n",
        "        third_party_perm = permission.split('.')[-1]\n",
        "        #print(f'3rd Party : {third_party_perm}')\n",
        "        manifest_pixels.append(sum(third_party_perm.encode())%256)\n",
        "        \n",
        "    #print(\"Uses Feature\")\n",
        "    for element in a.find_tags(\"uses-feature\"):\n",
        "        for key,value in element.items():\n",
        "            manifest_pixels.append(sum(f'uses-feature:{key}:{value}'.encode())%256)\n",
        "    \n",
        "    #print(f'Libraries : {a.get_libraries()}')\n",
        "    for lib in a.get_libraries():\n",
        "        manifest_pixels.append(sum(lib.encode())%256)\n",
        "    \n",
        "    #print(f'Meta Data : {a.find_tags(\"meta-data\")}')\n",
        "    for element in a.find_tags(\"meta-data\"):\n",
        "        for key,value in element.items():\n",
        "            manifest_pixels.append(sum(f'meta-data:{key}:{value}'.encode())%256)\n",
        "    \n",
        "    #print(\"Uses Configuration\")        \n",
        "    for element in a.find_tags(\"uses-configuration\"):\n",
        "        for key,value in element.items():\n",
        "            manifest_pixels.append(sum(f'uses-configuration:{key}:{value}'.encode())%256)\n",
        "    \n",
        "    #print(\"Queries\")\n",
        "    for element in a.find_tags(\"queries\"):\n",
        "        for key,value in element.items():\n",
        "             manifest_pixels.append(sum(f'queries:{key}:{value}'.encode())%256)\n",
        "    \n",
        "    #Activities\n",
        "    activities = a.get_activities()\n",
        "    for activity in activities:\n",
        "        manifest_pixels.append(sum(activity.encode())%256)\n",
        "            \n",
        "    #Services\n",
        "    services = a.get_services()\n",
        "    for service in services:\n",
        "        manifest_pixels.append(sum(service.encode())%256)\n",
        "            \n",
        "    #Recivers\n",
        "    receivers = a.get_receivers()\n",
        "    for receiver in receivers:\n",
        "        manifest_pixels.append(sum(receiver.encode())%256)\n",
        "            \n",
        "    #Providers\n",
        "    providers = a.get_providers()\n",
        "    for provider in providers:\n",
        "        manifest_pixels.append(sum(provider.encode())%256)\n",
        "        \n",
        "    #Intents\n",
        "    intents = []\n",
        "    manifest_list = {'permissions':permissions,'activity' : activities, 'service': services, 'receiver':receivers, 'provider':providers}\n",
        "    intents_itemtype = {'activity' : activities, 'service': services, 'receiver':receivers, 'provider':providers}\n",
        "    for itemtype, listt in intents_itemtype.items():\n",
        "        for item in listt:\n",
        "            try:\n",
        "                for intnts in a.get_intent_filters(itemtype, item).values():\n",
        "                    for intnt in intnts:\n",
        "                        #print(f'{itemtype}:{intnt}')\n",
        "                        manifest_pixels += list(f'{itemtype}:{intnt}'.encode())\n",
        "            except:\n",
        "                pass\n",
        "    if len(d) > 0 :\n",
        "        all_strings = d[0].get_strings()\n",
        "        #print(all_strings)\n",
        "        for strng in all_strings:\n",
        "            manifest_pixels.append((sum(strng.encode()))%256) \n",
        "    \n",
        "    #print(f\"Manifest pixels : {manifest_pixels}\")\n",
        "    green_channel = OneD2TwoD_resize(manifest_pixels, \"Green\", dim)\n",
        "    return green_channel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dab6942",
      "metadata": {
        "id": "4dab6942"
      },
      "outputs": [],
      "source": [
        "#Collecting properties (pixel values) from files, place on channel, resize the channel and merge to make an image\n",
        "def apk2image(a, d, dx, dim):\n",
        "    green_channel = manifest2Image(a,d,dim)    \n",
        "    red_channel, blue_channel = dex2Image(dx, dim)\n",
        "    image = cv2.merge((red_channel, green_channel, blue_channel))\n",
        "    image = image.astype(dtype='uint8')\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c00cf3",
      "metadata": {
        "id": "71c00cf3"
      },
      "outputs": [],
      "source": [
        "shas_list = []\n",
        "for path in glob.glob(\"C:/Users/palag/Documents/NCI/Semester_3/Research/apks/*\"):\n",
        "    shas_list.append(path.split(\"\\\\\")[1])\n",
        "print(shas_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b585e69",
      "metadata": {
        "id": "0b585e69"
      },
      "outputs": [],
      "source": [
        "shas_list = []\n",
        "for index, row in df_apk.iterrows():\n",
        "    shas_list.append(row['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c4a50c",
      "metadata": {
        "id": "b2c4a50c"
      },
      "outputs": [],
      "source": [
        "def get_md5_list(images_path, all_md5_list):\n",
        "    converted_imges = os.listdir(images_path)\n",
        "    converted_md5s = [md5[:-4] for md5 in converted_imges]\n",
        "    print(len(converted_imges), 'are converted.')\n",
        "\n",
        "    unconverted_md5_list = list(set(all_md5_list) - set(converted_md5s))\n",
        "    print(len(unconverted_md5_list), 'APKs are remaining to be converted.')\n",
        "    return converted_md5s, unconverted_md5_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "104a4644",
      "metadata": {
        "id": "104a4644"
      },
      "outputs": [],
      "source": [
        "DIM_64 = 64\n",
        "DIM_156 = 156\n",
        "\n",
        "img_dimension = DIM_156\n",
        "#Only for colab\n",
        "malware_imges_path = os.path.join('/content/gdrive/MyDrive/', f'dim_{img_dimension}p/')\n",
        "# malware_imges_path = os.path.join('C:/Users/palag/Documents/NCI/Semester_3/Research/images/', f'dim_{img_dimension}p/')\n",
        "\n",
        "try:\n",
        "    os.mkdir(malware_imges_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd42796",
      "metadata": {
        "id": "bcd42796"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03284821",
      "metadata": {
        "id": "03284821"
      },
      "outputs": [],
      "source": [
        "#Reading APK's SHA256 from downloaded APKs\n",
        "converted_shas = get_md5_list(malware_imges_path, shas_list)[0]\n",
        "\n",
        "to_be_converted_df = df_apk.copy()\n",
        "to_be_converted_df.set_index('id', inplace = True)\n",
        "to_be_converted_df.drop(converted_shas, axis = 0, inplace=True)\n",
        "to_be_converted_df.reset_index(inplace = True)\n",
        "\n",
        "i = 0\n",
        "for index, row in to_be_converted_df.iterrows():\n",
        "    print('Analysing :', row['id'])\n",
        "    \n",
        "    try:\n",
        "#         start = time.time()\n",
        "        #Androguard\n",
        "        a,d,dx = AnalyzeAPK(os.path.join(row['root_path'] + '/' + row['id'] + '.apk'))\n",
        "        img = apk2image(a, d, dx, img_dimension)\n",
        "#         end = time.time()\n",
        "#         print(f'Elapsed Time : {end - start}')\n",
        "        #Saving to local directory\n",
        "        cv2.imwrite(os.path.join(malware_imges_path + row['id'] + '.jpg'), img)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(traceback.format_exc())\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519a8a3c",
      "metadata": {
        "id": "519a8a3c"
      },
      "outputs": [],
      "source": [
        "#Create a DataFrame for converted apks\n",
        "unconverted_md5s = get_md5_list(malware_imges_path, shas_list)[1]\n",
        "converted_df = df_apk.copy()\n",
        "converted_df.set_index('id', inplace = True)\n",
        "converted_df.drop(unconverted_md5s, axis = 0, inplace=True)\n",
        "converted_df.reset_index(inplace = True)\n",
        "converted_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb262f2a",
      "metadata": {
        "id": "fb262f2a"
      },
      "outputs": [],
      "source": [
        "converted_df.to_csv(\"RGB_converted_APK_156p.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb98594c",
      "metadata": {
        "id": "fb98594c"
      },
      "outputs": [],
      "source": [
        "imges_path = 'C:/Users/palag/Documents/NCI/Semester_3/Research/images/'\n",
        "APKs_path = 'C:/Users/palag/Documents/NCI/Semester_3/Research/apks/'\n",
        "\n",
        "def apk2image_multi(sha):\n",
        "    apk = os.path.join(APKs_path + sha + '.apk')\n",
        "    print('Analysing :', apk[-68:])\n",
        "    \n",
        "    try:\n",
        "        #Androguard\n",
        "        a,d,dx = AnalyzeAPK(apk)\n",
        "\n",
        "        img = apk2image(a,d,dx)\n",
        "\n",
        "        #Saving to local directory\n",
        "        cv2.imwrite(os.path.join(imges_path + sha + '.jpg'), img)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e15d95e",
      "metadata": {
        "id": "5e15d95e"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "start_time = time.time()\n",
        "try:\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "        executor.map(apk2image_multi, apks_list[:100])\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    \n",
        "print(time.time()-start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8432c5",
      "metadata": {
        "id": "5b8432c5"
      },
      "source": [
        "# Making .npy file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only for colab\n",
        "families_npy_path = '/content/gdrive/MyDrive/'\n",
        "families_path = f'/content/gdrive/MyDrive/dim_{img_dimension}p/*'"
      ],
      "metadata": {
        "id": "HEdwciIjEPeN"
      },
      "id": "HEdwciIjEPeN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c82105",
      "metadata": {
        "id": "67c82105"
      },
      "outputs": [],
      "source": [
        "#converting images to numpy array (.npy file) for training deep learning models\n",
        "# families_path = f'C:/Users/palag/Documents/NCI/Semester_3/Research/images/dim_{img_dimension}p/*'\n",
        "\n",
        "# families_npy_path = 'C:/Users/palag/Documents/NCI/Semester_3/Research/npys/'\n",
        "\n",
        "from numpy import load\n",
        "count = 0\n",
        "array = []\n",
        "for family in glob.glob(families_path):\n",
        "    # image_name = family.split(\"\\\\\")[1]\n",
        "    image_name = family.split(\"/\")[-1]  #only for colab\n",
        "#     print(families_path[:-1] + image_name)\n",
        "    array.append(plt.imread(os.path.join(families_path[:-1] + image_name)))\n",
        "                 \n",
        "# np.save(os.path.join(families_npy_path + image_name[:-4] + '.npy'), array)\n",
        "np.save(os.path.join(families_npy_path + f'pixel_data_{img_dimension}p.npy'), array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd251f4",
      "metadata": {
        "id": "5dd251f4"
      },
      "outputs": [],
      "source": [
        "image_data = np.load(families_npy_path + f'pixel_data_{img_dimension}p.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab206d82",
      "metadata": {
        "id": "ab206d82"
      },
      "outputs": [],
      "source": [
        "image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e0114da",
      "metadata": {
        "id": "3e0114da"
      },
      "outputs": [],
      "source": [
        "converted_df['is_malicious'] = converted_df['label'].apply(lambda x : 0 if \"Benign\" in x else 1)\n",
        "converted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2bc399",
      "metadata": {
        "id": "6c2bc399"
      },
      "outputs": [],
      "source": [
        "y = converted_df['is_malicious'].values\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4381633",
      "metadata": {
        "id": "b4381633"
      },
      "outputs": [],
      "source": [
        "X_part, X_test, y_part, y_test = train_test_split(image_data, y, test_size=0.2, random_state=32)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_part, y_part, test_size=0.2, random_state=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344730a1",
      "metadata": {
        "id": "344730a1"
      },
      "outputs": [],
      "source": [
        "#Model Evaluation methods\n",
        "def scores(y_test, y_pred) :\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "def plot_model_performance(history, title):\n",
        "    # plot loss during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Loss')\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='test')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"./{title}_loss_vs_epoch.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # plot accuracy during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Accuracy')\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='test')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"./{title}_accuracy_vs_epoch.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, title):\n",
        "    plt.subplots(1, figsize=(10,10))\n",
        "    plt.title(title)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.plot([0, 1], ls=\"--\")\n",
        "    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.savefig(f'./{title}_roc_curve.png')\n",
        "    plt.show()\n",
        "\n",
        "def predict_and_evaluate(x_test, y_test, title):\n",
        "  prediction = model.predict(x_test)\n",
        "  # Get labels based on probability 1 if p>= 0.5 else 0\n",
        "  pred_labels = []\n",
        "  for pred in prediction:\n",
        "      if pred > 0.5:\n",
        "          pred_labels.append(1)\n",
        "      else:\n",
        "          pred_labels.append(0)\n",
        "  print(pred_labels)\n",
        "  print(\"AUC/ROC score is : \", roc_auc_score(y_test, pred_labels))\n",
        "  scores(y_test, pred_labels)\n",
        "  fpr,tpr, threshold = roc_curve(y_test, pred_labels)\n",
        "  plot_roc_curve(fpr, tpr, title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27295de4",
      "metadata": {
        "id": "27295de4"
      },
      "outputs": [],
      "source": [
        "#Creating the convolutional model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', strides = 1, input_shape=(156, 156, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', strides = 1))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c23c27d",
      "metadata": {
        "id": "5c23c27d"
      },
      "outputs": [],
      "source": [
        "#Adding dense layers on top\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc821b",
      "metadata": {
        "id": "1edc821b"
      },
      "outputs": [],
      "source": [
        "#Displaying the complete architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "157d3a97",
      "metadata": {
        "id": "157d3a97"
      },
      "outputs": [],
      "source": [
        "#Compiling and training the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f24c1b0",
      "metadata": {
        "id": "0f24c1b0"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(X_val,  y_val, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39546454",
      "metadata": {
        "id": "39546454"
      },
      "outputs": [],
      "source": [
        "#Printing thr test accuracy\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a117241",
      "metadata": {
        "id": "1a117241"
      },
      "outputs": [],
      "source": [
        "results = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62bafa90",
      "metadata": {
        "id": "62bafa90"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5598c5e",
      "metadata": {
        "id": "b5598c5e"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(results < 0.5, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98891f8",
      "metadata": {
        "id": "b98891f8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "scores(y_val, y_pred)\n",
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c5b789",
      "metadata": {
        "id": "72c5b789"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    hp_conv_layers = hp.Int(\"conv_layers\", 2, 4, default=3)\n",
        "    hp_dropout_rate=hp.Choice(\"dropout_rate\", values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]) \n",
        "    hp_activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'SGD', 'rmsprop'])\n",
        "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
        "    optimizer.learning_rate = hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001], default=0.01)\n",
        "    inputs = tf.keras.Input(shape=(156, 156, 3))\n",
        "    x=inputs\n",
        "   \n",
        "    for i in range(hp_conv_layers):\n",
        "        \n",
        "        x = tf.keras.layers.Conv2D(\n",
        "            filters=hp.Int(\"filters_\" + str(i), 4, 64, step=4, default=8),\n",
        "            kernel_size=hp.Int(\"kernel_size_\" + str(i), 3, 5),\n",
        "            activation=hp_activation,\n",
        "            padding=\"same\",\n",
        "        )(x)\n",
        "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = tf.keras.layers.Flatten()(x)    \n",
        "    x = tf.keras.layers.Dropout(hp_dropout_rate)(x)\n",
        "    \n",
        "    # The last layer contains 10 unitsfor the number of classes.\n",
        "    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer,\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeba54a1",
      "metadata": {
        "id": "aeba54a1"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    hyperband_iterations=2,\n",
        "    overwrite=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e04f33",
      "metadata": {
        "id": "d9e04f33"
      },
      "outputs": [],
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ec4f3fc",
      "metadata": {
        "id": "5ec4f3fc"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56089b01",
      "metadata": {
        "id": "56089b01"
      },
      "outputs": [],
      "source": [
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d4bdc6",
      "metadata": {
        "id": "a5d4bdc6"
      },
      "outputs": [],
      "source": [
        "# best_model.summary()\n",
        "history = best_model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770e1d8e",
      "metadata": {
        "id": "770e1d8e"
      },
      "outputs": [],
      "source": [
        "# best_hyperparameters.values\n",
        "scores(y_val, np.where(best_model.predict(X_val) < 0.5, 0, 1))\n",
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe15181",
      "metadata": {
        "id": "fbe15181"
      },
      "source": [
        "# ResNet50 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1173e10b",
      "metadata": {
        "id": "1173e10b"
      },
      "outputs": [],
      "source": [
        "#Resnet50 excluding topmost fully connected layer\n",
        "#Input shape (128, 128, 3)\n",
        "#Pooling : Global Average pooling\n",
        "#Optimizer : Adam\n",
        "base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape = (64, 64, 3), pooling = \"avg\")\n",
        "base_model.trainable = False\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(base_model.summary())\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eeabe0b",
      "metadata": {
        "id": "6eeabe0b"
      },
      "outputs": [],
      "source": [
        "#Compiling and training the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7a8fba",
      "metadata": {
        "id": "1c7a8fba"
      },
      "outputs": [],
      "source": [
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd4cc12",
      "metadata": {
        "id": "4bd4cc12"
      },
      "source": [
        "# EfficienetB4 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape_156 = (156, 156, 3)\n",
        "shape_64 = (64, 64, 3)\n",
        "input_shp =  shape_156"
      ],
      "metadata": {
        "id": "uaS7W9EsA6_Q"
      },
      "id": "uaS7W9EsA6_Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ecf3d31",
      "metadata": {
        "id": "7ecf3d31"
      },
      "outputs": [],
      "source": [
        "#EfficientNetB4 excluding topmost fully connected layer\n",
        "#Pooling : Global Average pooling\n",
        "#Optimizer : Adam\n",
        "base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_shape = input_shp, pooling = \"avg\")\n",
        "base_model.trainable = False\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "# print(base_model.summary())\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6420f55",
      "metadata": {
        "id": "b6420f55"
      },
      "outputs": [],
      "source": [
        "#Compiling and training the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42cbe7b4",
      "metadata": {
        "id": "42cbe7b4"
      },
      "outputs": [],
      "source": [
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientB4 Hyperparameter Tuning Using HyperBand"
      ],
      "metadata": {
        "id": "rfA7fNGE_Igd"
      },
      "id": "rfA7fNGE_Igd"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_efficientb4_model(hp):\n",
        "    # hp_conv_layers = hp.Int(\"conv_layers\", 2, 4, default=3)\n",
        "    hp_dense_layers = hp.Int(\"dense_layers\", 1, 4, default=3)\n",
        "    hp_dense_units = hp.Int(\"dense_units\", 4, 64, step = 4, default = 2)\n",
        "    hp_dropout_rate=hp.Choice(\"dropout_rate\", values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]) \n",
        "    hp_activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'SGD', 'rmsprop'])\n",
        "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
        "    optimizer.learning_rate = hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001], default=0.01)\n",
        "    inputs = tf.keras.Input(shape=input_shp)\n",
        "    x=inputs\n",
        "    base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_shape = input_shp, pooling = \"avg\")\n",
        "    base_model.trainable = False\n",
        "    x = base_model(x)\n",
        "    for i in range(hp_dense_layers):\n",
        "        x = tf.keras.layers.Dense(hp_dense_units, activation=hp_activation)(x)\n",
        "    x = tf.keras.layers.Dropout(hp_dropout_rate)(x)\n",
        "\n",
        "    # The last layer contains 10 unitsfor the number of classes.\n",
        "    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer,\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "QhDYKSY1_O-3"
      },
      "id": "QhDYKSY1_O-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effb4_tuner = kt.Hyperband(\n",
        "    build_efficientb4_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    hyperband_iterations=2,\n",
        "    overwrite=True)"
      ],
      "metadata": {
        "id": "egGoG7kY_UZx"
      },
      "id": "egGoG7kY_UZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effb4_tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "KPFKHb7t_mAW"
      },
      "id": "KPFKHb7t_mAW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_effb4_model = tuner.get_best_models(1)[0]\n",
        "best_effb4_hyperparameters = tuner.get_best_hyperparameters(1)[0]"
      ],
      "metadata": {
        "id": "tespzBd6_q5U"
      },
      "id": "tespzBd6_q5U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_effb4_model.summary()"
      ],
      "metadata": {
        "id": "aIywc9Io_zG8"
      },
      "id": "aIywc9Io_zG8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effb4_tuner.results_summary()"
      ],
      "metadata": {
        "id": "0xdnpXOs_0Ja"
      },
      "id": "0xdnpXOs_0Ja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling and training the model\n",
        "best_effb4_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "effb4_history = best_effb4_model.fit(X_train, y_train, epochs=30, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "ivgfvqiZ_9Ia"
      },
      "id": "ivgfvqiZ_9Ia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_evaluate(X_val, y_val, \"EfficientB4\")\n",
        "plot_model_performance(effb4_history, \"EfficientB4\")"
      ],
      "metadata": {
        "id": "UKALBUtgAOMR"
      },
      "id": "UKALBUtgAOMR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}