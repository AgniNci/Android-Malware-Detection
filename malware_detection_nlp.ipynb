{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b67a7b",
      "metadata": {
        "id": "f2b67a7b"
      },
      "outputs": [],
      "source": [
        "from androguard.misc import AnalyzeAPK\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randrange\n",
        "import sys\n",
        "import os\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import save_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import datasets, layers, models, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "import keras_tuner as kt\n",
        "from kerastuner import HyperParameter, HyperParameters\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only required while running the notebook on colab\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "KMd-lNsRFBwQ"
      },
      "id": "KMd-lNsRFBwQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0b53d424",
      "metadata": {
        "id": "0b53d424"
      },
      "source": [
        "# Load Apk Data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da52e42",
      "metadata": {
        "id": "5da52e42"
      },
      "outputs": [],
      "source": [
        "df_apk = pd.read_csv(\"apk_data.csv\")\n",
        "df_apk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faee2593",
      "metadata": {
        "id": "faee2593"
      },
      "outputs": [],
      "source": [
        "df_apk['is_malicious'] = df_apk['label'].apply(lambda x : 0 if \"Benign\" in x else 1)\n",
        "df_apk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc70f96",
      "metadata": {
        "id": "3dc70f96"
      },
      "source": [
        "# Extract opcodes from dex files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566a50d",
      "metadata": {
        "id": "9566a50d"
      },
      "outputs": [],
      "source": [
        "OPCODE_FILE_PATH = \"../../Research/nlp_opcode_sequences/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7525c7",
      "metadata": {
        "id": "ee7525c7"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.mkdir(OPCODE_FILE_PATH)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10bf214e",
      "metadata": {
        "id": "10bf214e"
      },
      "outputs": [],
      "source": [
        "def get_md5_list(images_path, all_md5_list):\n",
        "    converted_imges = os.listdir(images_path)\n",
        "    converted_md5s = [md5[:-4] for md5 in converted_imges]\n",
        "    print(len(converted_imges), 'are converted.')\n",
        "    unconverted_md5_list = list(set(all_md5_list) - set(converted_md5s))\n",
        "    print(len(unconverted_md5_list), 'APKs are remaining to be converted.')\n",
        "    return converted_md5s, unconverted_md5_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8b5832",
      "metadata": {
        "id": "6f8b5832"
      },
      "outputs": [],
      "source": [
        "#Opcode Sequence Extraction from dex files\n",
        "def apk_to_api_sequences(a, d, dx):\n",
        "    methods = []\n",
        "    for m_a in dx.get_methods():\n",
        "        m = m_a.get_method()\n",
        "        if m_a.is_external():\n",
        "        # External methods do not have opcodes\n",
        "            continue\n",
        "        idx = 0\n",
        "        method_opcodes = []\n",
        "        for ins in m.get_instructions():\n",
        "            # You can access the instruction here and do stuff with it... \n",
        "            method_opcodes.append(ins.get_name( ))\n",
        "            idx += ins.get_length()\n",
        "        methods.append(\"\".join(method_opcodes).strip())\n",
        "    print(f'All Methods Count: {len(methods)}')\n",
        "    unique_methods = list(set(methods))\n",
        "    print(f'All Unique Methods Count: {len(unique_methods)}')\n",
        "    return unique_methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575710cc",
      "metadata": {
        "id": "575710cc"
      },
      "outputs": [],
      "source": [
        "shas_list = []\n",
        "for index, row in df_apk.iterrows():\n",
        "    shas_list.append(row['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b0a124",
      "metadata": {
        "id": "a6b0a124"
      },
      "outputs": [],
      "source": [
        "converted_shas = get_md5_list(OPCODE_FILE_PATH, shas_list)[0]\n",
        "\n",
        "to_be_converted_df = df_apk.copy()\n",
        "to_be_converted_df.set_index('id', inplace = True)\n",
        "to_be_converted_df.drop(converted_shas, axis = 0, inplace=True)\n",
        "to_be_converted_df.reset_index(inplace = True)\n",
        "\n",
        "for index, row in to_be_converted_df.iterrows():\n",
        "    print('Analysing :', row['id'])\n",
        "    \n",
        "    try:\n",
        "        #Androguard\n",
        "        a,d,dx = AnalyzeAPK(os.path.join(row['root_path'] + '/' + row['id'] + '.apk'))\n",
        "        opc = apk_to_api_sequences(a,d,dx)\n",
        "        np.savetxt(os.path.join(OPCODE_FILE_PATH + row['id'] + '.txt'), opc, fmt=\"%s\", delimiter = \" \")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2e3b49",
      "metadata": {
        "id": "6e2e3b49"
      },
      "outputs": [],
      "source": [
        "#Create a DataFrame for converted apks\n",
        "unconverted_md5s = get_md5_list(OPCODE_FILE_PATH, shas_list)[1]\n",
        "converted_df = df_apk.copy()\n",
        "converted_df.set_index('id', inplace = True)\n",
        "converted_df.drop(unconverted_md5s, axis = 0, inplace=True)\n",
        "converted_df.reset_index(inplace = True)\n",
        "converted_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_df"
      ],
      "metadata": {
        "id": "25ElUu7VFuXv"
      },
      "id": "25ElUu7VFuXv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723bb1a4",
      "metadata": {
        "id": "723bb1a4"
      },
      "outputs": [],
      "source": [
        "converted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0d32ce",
      "metadata": {
        "id": "de0d32ce"
      },
      "outputs": [],
      "source": [
        "converted_df.drop(columns = ['root_path'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11b7871",
      "metadata": {
        "id": "d11b7871"
      },
      "outputs": [],
      "source": [
        "converted_df['opcode_path'] = converted_df['id'].apply(lambda x : os.path.join(OPCODE_FILE_PATH + x + '.txt'))\n",
        "converted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d842c0",
      "metadata": {
        "id": "a9d842c0"
      },
      "outputs": [],
      "source": [
        "def sample_sequences_from_text(text_list, num_sequences, seq_size = 420):\n",
        "    sub_sample_sizes = [int(seq_size * 0.4), int(seq_size * 0.3), int(seq_size * 0.2), int(seq_size * 0.1)]\n",
        "    #print(f'Sub Sample Sizes : {sub_sample_sizes}')\n",
        "    chunks = np.array_split(text_list, len(sub_sample_sizes))\n",
        "    sequences = []\n",
        "    for num in range(num_sequences):\n",
        "        np.random.shuffle(chunks)\n",
        "        seq = []\n",
        "        for i in range(len(sub_sample_sizes)):\n",
        "            seq += np.ndarray.tolist(chunks[i][:sub_sample_sizes[i]])\n",
        "        sequences.append(\" \".join(seq))\n",
        "        \n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d326ad9",
      "metadata": {
        "id": "1d326ad9"
      },
      "outputs": [],
      "source": [
        "#Sampling sequence data for language models\n",
        "def create_records():\n",
        "    try:\n",
        "        for index, row in converted_df.iterrows():\n",
        "            print(f'Index : {index}')\n",
        "            with open(row[\"opcode_path\"], 'r') as f:\n",
        "                text = f.read()\n",
        "                unique_opseq_list = text.split(\"\\n\")\n",
        "                samples = []\n",
        "                if len(unique_opseq_list) > 600:\n",
        "                    samples += sample_sequences_from_text(unique_opseq_list, 2)\n",
        "                else:\n",
        "                    samples.append(text.replace(\"\\n\", \" \"))\n",
        "                count = 0\n",
        "                for sample in samples:\n",
        "                    if count > 0:\n",
        "                        yield {\"file_name\" : f'{f.name}{count}', \"opcode\" : sample, \"is_malicious\" : row[\"is_malicious\"]}\n",
        "                    else:\n",
        "                        yield {\"file_name\" : f.name, \"opcode\" : sample, \"is_malicious\" : row[\"is_malicious\"]}\n",
        "                    count += 1\n",
        "    except Exception as e:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d9f495",
      "metadata": {
        "id": "70d9f495"
      },
      "outputs": [],
      "source": [
        "opcode_list = []\n",
        "for record in create_records():\n",
        "    opcode_list.append(record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5968ab",
      "metadata": {
        "id": "eb5968ab"
      },
      "outputs": [],
      "source": [
        "opcode_df = pd.DataFrame(opcode_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026ac5dc",
      "metadata": {
        "id": "026ac5dc"
      },
      "outputs": [],
      "source": [
        "opcode_df\n",
        "# Required when running the notebook from colab\n",
        "# opcode_df = pd.read_csv(\"/content/gdrive/MyDrive/opcode.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opcode_df.isnull().sum()"
      ],
      "metadata": {
        "id": "fo-GeXhKJdsr"
      },
      "id": "fo-GeXhKJdsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opcode_df.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "J-P6sctWJjlN"
      },
      "id": "J-P6sctWJjlN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377a7e07",
      "metadata": {
        "id": "377a7e07"
      },
      "outputs": [],
      "source": [
        "opcode_df[\"is_malicious\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffling and Splitting the dataset into training and test\n",
        "shuffled_opcode_df = opcode_df.sample(frac = 1).reset_index()\n",
        "train_opcode_df = shuffled_opcode_df.iloc[20:3670, :]\n",
        "test_opcode_df = shuffled_opcode_df.iloc[:20,:]"
      ],
      "metadata": {
        "id": "MMto6JfKISR4"
      },
      "id": "MMto6JfKISR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b34626",
      "metadata": {
        "id": "e8b34626"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_opcode_df[\"opcode\"], train_opcode_df[\"is_malicious\"], random_state = 100, train_size = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc6dedf",
      "metadata": {
        "id": "5cc6dedf"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdaf29d2",
      "metadata": {
        "id": "cdaf29d2"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09af336b",
      "metadata": {
        "id": "09af336b"
      },
      "outputs": [],
      "source": [
        "#Model Evaluation methods\n",
        "def scores(y_test, y_pred) :\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    print('Precision: %f' % precision)\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    print('Recall: %f' % recall)\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print('F1 score: %f' % f1)\n",
        "\n",
        "\n",
        "def plot_model_performance(history):\n",
        "    # plot loss during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Loss')\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='test')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "#     plt.savefig(\"./loss_vs_epoch.png\")\n",
        "\n",
        "    # plot accuracy during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Accuracy')\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='test')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "#Plot val loss for multiple models\n",
        "def plot_model_val_loss(histories):\n",
        "    # plot loss during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Loss')\n",
        "    for name, history in histories.items():\n",
        "    # plt.plot(history.history['loss'], label='train')\n",
        "      plt.plot(history.history['val_loss'], label=name)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "#     plt.savefig(\"./loss_vs_epoch.png\")\n",
        "\n",
        "#Plot val accuracy for multiple models\n",
        "def plot_model_val_accuracy(histories):\n",
        "    # plot accuracy during training\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.title('Accuracy')\n",
        "    for name, history in histories.items():\n",
        "    # plt.plot(history.history['accuracy'], label='train')\n",
        "      plt.plot(history.history['val_accuracy'], label=name)\n",
        "    plt.grid(True)\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6d8513",
      "metadata": {
        "id": "eb6d8513"
      },
      "source": [
        "# Logistic Regression with CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e28d6ea9",
      "metadata": {
        "id": "e28d6ea9"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(input = 'content', ngram_range = (1,2), min_df = 5, token_pattern = r\"[a-z0-9-\\/]+\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af7873b",
      "metadata": {
        "id": "0af7873b"
      },
      "outputs": [],
      "source": [
        "vectorizer.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9135869",
      "metadata": {
        "id": "a9135869"
      },
      "outputs": [],
      "source": [
        "X_train_vectorized = vectorizer.transform(X_train)\n",
        "X_train_vectorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df42040f",
      "metadata": {
        "id": "df42040f"
      },
      "outputs": [],
      "source": [
        "print(X_train_vectorized.toarray()[:10])\n",
        "X_train_vectorized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de3dd1cf",
      "metadata": {
        "id": "de3dd1cf"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47ad658",
      "metadata": {
        "id": "f47ad658"
      },
      "outputs": [],
      "source": [
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "predictions = model.predict(X_test_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8778516a",
      "metadata": {
        "id": "8778516a"
      },
      "outputs": [],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a608c3b",
      "metadata": {
        "id": "3a608c3b"
      },
      "outputs": [],
      "source": [
        "print(\"AUC/ROC score is : \", roc_auc_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vectorized = vectorizer.transform(test_opcode_df['opcode'])\n",
        "predictions = model.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "KIfXkjdeJ_Vt"
      },
      "id": "KIfXkjdeJ_Vt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AUC/ROC score is : \", roc_auc_score(test_opcode_df['is_malicious'], predictions))"
      ],
      "metadata": {
        "id": "2mLGuQcoKloN"
      },
      "id": "2mLGuQcoKloN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores(test_opcode_df['is_malicious'], predictions)"
      ],
      "metadata": {
        "id": "-DmNl_HcMul8"
      },
      "id": "-DmNl_HcMul8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8c1b9a65",
      "metadata": {
        "id": "8c1b9a65"
      },
      "source": [
        "# Implementing LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0fcdd6",
      "metadata": {
        "id": "bb0fcdd6"
      },
      "outputs": [],
      "source": [
        "corpus = \" \".join(opcode_df[\"opcode\"].tolist())\n",
        "vocab = sorted(list(set(corpus.split(\" \"))))[1:]\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d15fc5f",
      "metadata": {
        "id": "7d15fc5f"
      },
      "outputs": [],
      "source": [
        "#Setting Hyperparameters for Keras Tokenizer\n",
        "vocab_size = len(vocab)\n",
        "oov_tok = ''\n",
        "embedding_dim = 100\n",
        "max_length = 200 # choose based on statistics, for example 150 to 200\n",
        "padding_type='post'\n",
        "trunc_type='post'\n",
        "# tokenize sentences\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok, filters=\"\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "# convert train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
        "# convert Test dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
        "print(f'Word Index Length : {len(word_index)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbb752a",
      "metadata": {
        "id": "4dbb752a"
      },
      "outputs": [],
      "source": [
        "#Initializing LSTM model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length = max_length))\n",
        "# LSTM\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86357c50",
      "metadata": {
        "id": "86357c50"
      },
      "outputs": [],
      "source": [
        "#Compiling and Fitting LSTM model with the training data\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_padded, y_train, validation_data=(test_padded, y_test),epochs=30, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing dictionary to hold multiplt history instances\n",
        "histories ={}"
      ],
      "metadata": {
        "id": "XKgzD2lKPJNX"
      },
      "id": "XKgzD2lKPJNX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories['LSTM'] = history"
      ],
      "metadata": {
        "id": "dwQDsDwaPNX7"
      },
      "id": "dwQDsDwaPNX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b97321",
      "metadata": {
        "id": "96b97321"
      },
      "outputs": [],
      "source": [
        "#Predictions\n",
        "prediction = model.predict(test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc1540c",
      "metadata": {
        "id": "fdc1540c"
      },
      "outputs": [],
      "source": [
        "# Get labels based on probability 1 if p>= 0.5 else 0\n",
        "pred_labels = []\n",
        "for pred in prediction:\n",
        "    if pred > 0.5:\n",
        "        pred_labels.append(1)\n",
        "    else:\n",
        "        pred_labels.append(0)\n",
        "print(pred_labels)\n",
        "print(\"AUC/ROC score is : \", roc_auc_score(y_test, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846453fc",
      "metadata": {
        "id": "846453fc"
      },
      "outputs": [],
      "source": [
        "scores(y_test, pred_labels)\n",
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727debbb",
      "metadata": {
        "id": "727debbb"
      },
      "outputs": [],
      "source": [
        "save_model(model, \"../lstm/opcode_nlp_novel_sequencing_13122022_0534.h5\", save_format = \"h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6001e7",
      "metadata": {
        "id": "ac6001e7"
      },
      "source": [
        "# Bidirectional LSTM with Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967d3ee0",
      "metadata": {
        "id": "967d3ee0"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length = max_length))\n",
        "# LSTM\n",
        "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3f239f",
      "metadata": {
        "id": "aa3f239f"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_padded, y_train, validation_data=(test_padded, y_test),epochs=30, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "histories['Bi-LSTM'] = history"
      ],
      "metadata": {
        "id": "qAaf-y7CQc3r"
      },
      "id": "qAaf-y7CQc3r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_val_loss(histories)\n",
        "plot_model_val_accuracy(histories)"
      ],
      "metadata": {
        "id": "AlSu5S7_Qt6a"
      },
      "id": "AlSu5S7_Qt6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f28db2fb",
      "metadata": {
        "id": "f28db2fb"
      },
      "outputs": [],
      "source": [
        "scores(y_test, pred_labels)\n",
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7190ad",
      "metadata": {
        "id": "fe7190ad"
      },
      "source": [
        "# Word2Vec Training and Embedding Matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ffc6a8",
      "metadata": {
        "id": "51ffc6a8"
      },
      "outputs": [],
      "source": [
        "#Modifying input data for passing into word2vec model\n",
        "embedding_input = [x.split(\" \") for x in X_train.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085c5d6b",
      "metadata": {
        "id": "085c5d6b"
      },
      "outputs": [],
      "source": [
        "#Word2Vec Vectorization\n",
        "w2v = Word2Vec(embedding_input, vector_size=100,\n",
        "                                   window=5,\n",
        "                                   min_count=2,\n",
        "                                   workers = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gensim.__version__)"
      ],
      "metadata": {
        "id": "7IMVxtvASCdv"
      },
      "id": "7IMVxtvASCdv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f63279a",
      "metadata": {
        "id": "6f63279a"
      },
      "outputs": [],
      "source": [
        "w2v.wv.index_to_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5d539f",
      "metadata": {
        "id": "7d5d539f"
      },
      "outputs": [],
      "source": [
        "len(w2v.wv.index_to_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24306b3a",
      "metadata": {
        "id": "24306b3a"
      },
      "outputs": [],
      "source": [
        "# Initializing Keras Tokenizer with HyperParameters\n",
        "vocab_size = len(vocab)\n",
        "oov_tok = ''\n",
        "embedding_dim = 100\n",
        "max_length = 200 # choose based on statistics, for example 150 to 200\n",
        "padding_type='post'\n",
        "trunc_type='post'\n",
        "# tokenize sentences\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok, filters = \"\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "# convert train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
        "# convert Test dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
        "print(f'Vocab Size : {vocab_size}')\n",
        "print(f'Word Index Length : {len(word_index)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a737c1",
      "metadata": {
        "id": "30a737c1"
      },
      "outputs": [],
      "source": [
        "#Save the generated word vectors in the local file system \n",
        "word_vectors = w2v.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9e9bb2",
      "metadata": {
        "id": "9f9e9bb2"
      },
      "outputs": [],
      "source": [
        "word_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04da6cb9",
      "metadata": {
        "id": "04da6cb9"
      },
      "outputs": [],
      "source": [
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap = 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ab3c27",
      "metadata": {
        "id": "39ab3c27"
      },
      "outputs": [],
      "source": [
        "#Preparing embedding matrix\n",
        "nb_words = min(vocab_size, len(word_index))+1\n",
        "embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in wv.index_to_key:\n",
        "        embedding_matrix[i] = wv.get_vector(word)\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f4d400",
      "metadata": {
        "id": "24f4d400"
      },
      "outputs": [],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc43010c",
      "metadata": {
        "id": "bc43010c"
      },
      "source": [
        "# Bidirectional LSTM with Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a9ca14",
      "metadata": {
        "id": "c1a9ca14"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "vocab_size = nb_words\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = max_length, trainable = False))\n",
        "# LSTM\n",
        "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425abf71",
      "metadata": {
        "id": "425abf71"
      },
      "outputs": [],
      "source": [
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449fad27",
      "metadata": {
        "id": "449fad27"
      },
      "outputs": [],
      "source": [
        "es_callback = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_padded, y_train, validation_data=(test_padded, y_test),epochs=10, verbose=2, callbacks=[es_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5aae85",
      "metadata": {
        "id": "eb5aae85"
      },
      "outputs": [],
      "source": [
        "scores(y_test, pred_labels)\n",
        "plot_model_performance(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "vocab_size = nb_words\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = max_length, trainable = False))\n",
        "# LSTM\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "KsYM-HW2UvLA"
      },
      "id": "KsYM-HW2UvLA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_padded, y_train, validation_data=(test_padded, y_test),epochs=10, verbose=2)"
      ],
      "metadata": {
        "id": "rZEXaZQRVCub"
      },
      "id": "rZEXaZQRVCub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e91fba",
      "metadata": {
        "id": "57e91fba"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameter tuning using Hyperband algorithm from keras\n",
        "def build_model(hp):\n",
        "    hp_lstm_units = hp.Int(\"lstm_units\", 32, 256, step = 32, default = 64)\n",
        "    hp_dense_layers = hp.Int(\"dense_layers\", 1, 4, default=3)\n",
        "    hp_dropout_rate=hp.Choice(\"dropout_rate\", values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5]) \n",
        "    hp_activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'SGD', 'rmsprop'])\n",
        "    optimizer = tf.keras.optimizers.get(hp_optimizer)\n",
        "    optimizer.learning_rate = hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001], default=0.01)\n",
        "    inputs = tf.keras.Input(shape=(200,))\n",
        "    x=inputs\n",
        "   \n",
        "    x = layers.Embedding(vocab_size, embedding_dim, weights = [embedding_matrix], input_length = max_length, trainable = False)(x)\n",
        "# LSTM\n",
        "    x = layers.Bidirectional(layers.LSTM(hp_lstm_units))(x)\n",
        "    for i in range(hp_dense_layers):\n",
        "        \n",
        "        x = layers.Dense(\n",
        "            units=hp.Int(\"units_\" + str(i), 4, 64, step=4, default=8),\n",
        "            activation=hp_activation\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(hp_dropout_rate)(x)\n",
        "    \n",
        "    # The last layer contains 10 unitsfor the number of classes.\n",
        "    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer,\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53bc8bf",
      "metadata": {
        "id": "a53bc8bf"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    hyperband_iterations=2,\n",
        "    overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_padded, y_train, epochs=10, validation_data=(test_padded, y_test))"
      ],
      "metadata": {
        "id": "Y0UbQr6fWH6D"
      },
      "id": "Y0UbQr6fWH6D",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}